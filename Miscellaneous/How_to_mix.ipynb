{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "195fafac",
   "metadata": {},
   "source": [
    "# $\\color{Darkred}{\\text{How-to Miscellaneous}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf25346",
   "metadata": {},
   "source": [
    "The notebook is a demo for the implementation of the results regarding general purpose algorithms for the Subspace Clustering problem. It is divided in three sections:\n",
    "\n",
    "* **Import:** Import the .py script which we implemented along with the basic Python packages. \n",
    "* **Principal Component Analysis:** Analysis of the MSE for the Subspace Clustering problem achieved by *PCA* and *sparse PCA*.\n",
    "* **Diagonal Thresholding:** Analysis of the MSE for the Subspace Clustering problem achieved by *Diagonal Thresholding algorithm*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb0f97",
   "metadata": {},
   "source": [
    "### $\\color{Darkred}{\\text{Import}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c27ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Mix_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3682a725",
   "metadata": {},
   "source": [
    "### $\\color{Darkred}{\\text{Principal Component Analysis}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e0572",
   "metadata": {},
   "source": [
    "PCA is a spectral algorithm that looks at the eigenvectors of the covariance matrix. Sparse PCA (SPCA), on the other hand, imposes that the principal components which we find will have some non-zero components. We work in a Bayesian setting in which we assume that the statistician will know what is the sparsity level $\\rho$, and she can tune the sparsity imposed by SPCA. The implementation of both algorithm can be done thanks to Sklearn package https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de705237",
   "metadata": {},
   "source": [
    "Fix a sparsity level $\\rho$, say $\\rho=0.01$. After generating the data matrix, we can find the optimal parameters for the SPCA algorithm such that the estimated sparsity coincides with the true one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6342b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start the loop\n",
      "At iteration 0 we have regularization parameter = 0.05. \n",
      "The estimated number of non-zero components is 28 while the true number is 10\n",
      "At iteration 1 we have regularization parameter = 0.052000000000000005. \n",
      "The estimated number of non-zero components is 24 while the true number is 10\n",
      "At iteration 2 we have regularization parameter = 0.05408000000000001. \n",
      "The estimated number of non-zero components is 20 while the true number is 10\n",
      "At iteration 3 we have regularization parameter = 0.056243200000000014. \n",
      "The estimated number of non-zero components is 19 while the true number is 10\n",
      "At iteration 4 we have regularization parameter = 0.05849292800000001. \n",
      "The estimated number of non-zero components is 16 while the true number is 10\n",
      "At iteration 5 we have regularization parameter = 0.060832645120000015. \n",
      "The estimated number of non-zero components is 15 while the true number is 10\n",
      "At iteration 6 we have regularization parameter = 0.06326595092480002. \n",
      "The estimated number of non-zero components is 12 while the true number is 10\n",
      "At iteration 7 we have regularization parameter = 0.06579658896179202. \n",
      "The estimated number of non-zero components is 11 while the true number is 10\n"
     ]
    }
   ],
   "source": [
    "rho , dimension , nsamples = 0.01 , 1000 , 2000 \n",
    "alpha = nsamples / dimension\n",
    "snr = 1.5/(rho*np.sqrt(alpha))\n",
    "u0,v0,X = get_instance(rho, dimension, nsamples, snr)\n",
    "# Find best regularization parameter in the LASSO problem \n",
    "Gamma = oracle(X,rho,damp = 0.99,max_steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b766b2f9",
   "metadata": {},
   "source": [
    "Once found the best regularization parameter, $\\Gamma_{opt}$, we can exploit the Sklearn package to solve the sparse PCA problem and compute the cluster assignments. By setting the regularization parameter to zero we obtain the vanilla PCA algorithm trivially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c753b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE achieved by SPCA is 0.236 \n",
      "The MSE achieved by PCA is 0.386\n"
     ]
    }
   ],
   "source": [
    "mse_spca  = SPCA(X,u0,v0,Gamma)\n",
    "mse_pca  = SPCA(X,u0,v0,0)\n",
    "print(f'The MSE achieved by SPCA is {mse_spca} \\nThe MSE achieved by PCA is {mse_pca}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b5bfac",
   "metadata": {},
   "source": [
    "### $\\color{Darkred}{\\text{Diagonal Thresholding}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21c1b9d",
   "metadata": {},
   "source": [
    "In this section we implement the Diagonal Thresholding algorithm. We are always in a Bayesian setting and the statistician knows what is the sparsity level at which we operate. The main idea is to search for spatial directions with the largest variance, and threshold the sample covariance matrix\n",
    "accordingly. The algorithm works well at very high sparsity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82221c07",
   "metadata": {},
   "source": [
    "Consider for example the case in which the relevant features live in a three-dimensional subspace. In the language of the paper $s_0 =3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0980505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE achieved by Diagonal Thresholding is [0.329]\n"
     ]
    }
   ],
   "source": [
    "nsamples , dimension , s0 = 2000,1000,3\n",
    "mse_dtr = dtr(n=nsamples,d=dimension,s0=s0)\n",
    "print(f'The MSE achieved by Diagonal Thresholding is {mse_dtr}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
